#!/usr/bin/env python3
"""
pretrain.ipynb ìƒì„¸ ë¶„ì„ ë° ì„¤ëª…
- Self-Supervised Learning ì™„ì „ ì´í•´
"""

print("ğŸ§  pretrain.ipynb ìƒì„¸ ë¶„ì„ - Self-Supervised Learning")
print("=" * 70)

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import pytorch_lightning as pl
import random

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ import
from src.util import random_crop, random_mask, random_multiply
from src.model.models_cola import Cola, ColaMD, SimpleEncoder

print("\nğŸ“š 1ë‹¨ê³„: Self-Supervised Learning ê°œë… ì´í•´")
print("-" * 50)

print("""
ğŸ¯ Self-Supervised Learningì´ë€?

ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹:
ë°ì´í„° + ë¼ë²¨ â†’ ëª¨ë¸ í•™ìŠµ â†’ ì˜ˆì¸¡

Self-Supervised Learning:
ë°ì´í„°ë§Œ â†’ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ íŒ¨í„´ í•™ìŠµ â†’ íŠ¹ì§• ì¶”ì¶œ

í•µì‹¬ ì•„ì´ë””ì–´:
- "ë°ì´í„° ìì²´ê°€ ì„ ìƒë‹˜"
- ë¼ë²¨ ì—†ì´ë„ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ íŒ¨í„´ì„ í•™ìŠµ
- ì¼ë°˜í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— í™œìš©
""")

print("\nğŸ”§ 2ë‹¨ê³„: AudioDataset í´ë˜ìŠ¤ ìƒì„¸ ë¶„ì„")
print("-" * 50)

class AudioDataset(torch.utils.data.Dataset):
    """
    ì˜¤ë””ì˜¤ (ìŠ¤í™íŠ¸ë¡œê·¸ë¨) ë°ì´í„°ë¥¼ contrastive í•™ìŠµ ë°©ì‹(cola)ì— ë§ê²Œ
    x1, x2ë¡œ ì¦ê°•í•˜ì—¬ ë¦¬í„´í•˜ëŠ” Dataset í´ë˜ìŠ¤
    """
    def __init__(
        self, data, max_len=200, augment=True, from_npy=False,
        labels=None, method="cola"
    ):
        self.data = data
        self.max_len = max_len
        self.augment = augment
        self.from_npy = from_npy
        self.labels = labels
        self.method = method

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # npy íŒŒì¼ë¡œë¶€í„° ë¡œë“œí• ì§€ ì—¬ë¶€ ê²°ì •
        if self.from_npy:
            npy_path = self.data[idx]
            x = np.load(npy_path)
        else:
            x = self.data[idx]

        if self.method == "cola":
            # ì½œë¼ ë°©ì‹ ì¦ê°•
            if self.augment:
                x = random_mask(x)

            x1 = random_crop(x, crop_size=self.max_len)
            x2 = random_crop(x, crop_size=self.max_len)
            
            return x1, x2
        else:
            # ì¼ë°˜ì ì¸ ê²½ìš°
            if self.labels is not None:
                return x, self.labels[idx]
            else:
                return x

print("""
ğŸ“‹ AudioDataset í´ë˜ìŠ¤ì˜ í•µì‹¬ ê¸°ëŠ¥:

1. __init__():
   - data: ì˜¤ë””ì˜¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
   - max_len: í¬ë¡­í•  ê¸¸ì´ (ê¸°ë³¸ 200)
   - augment: ë°ì´í„° ì¦ê°• ì—¬ë¶€
   - method: "cola" (contrastive learning)

2. __getitem__():
   - ê°™ì€ ì˜¤ë””ì˜¤ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë³€í˜• ìƒì„±
   - x1, x2: Positive pairs (ê°™ì€ ì˜¤ë””ì˜¤ì˜ ë‹¤ë¥¸ êµ¬ê°„)
   - random_mask: ë…¸ì´ì¦ˆ ê°•ê±´ì„±ì„ ìœ„í•œ ë§ˆìŠ¤í‚¹
   - random_crop: ì‹œê°„ì  ë‹¤ì–‘ì„±ì„ ìœ„í•œ í¬ë¡­í•‘

3. Contrastive Learningì˜ í•µì‹¬:
   - Positive pairs: ê°™ì€ ì˜¤ë””ì˜¤ì˜ ë³€í˜•ë“¤ (ê°€ê¹ê²Œ í•™ìŠµ)
   - Negative pairs: ë‹¤ë¥¸ ì˜¤ë””ì˜¤ì˜ ë³€í˜•ë“¤ (ë©€ê²Œ í•™ìŠµ)
""")

print("\nğŸ§ª 3ë‹¨ê³„: AudioDataset ì‹¤ì œ í…ŒìŠ¤íŠ¸")
print("-" * 50)

# ë”ë¯¸ ë°ì´í„° ìƒì„±
print("ë”ë¯¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë°ì´í„° ìƒì„±...")
dummy_data = []
for i in range(10):
    # ê°ê° ë‹¤ë¥¸ íŒ¨í„´ì˜ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
    if i % 2 == 0:
        # ì •ìƒ í˜¸í¡ìŒ íŒ¨í„´ (ì €ì£¼íŒŒìˆ˜ ê°•í•¨)
        spec = np.random.randn(200, 128)
        spec[:, :32] *= 2  # ì €ì£¼íŒŒìˆ˜ ê°•í™”
    else:
        # ë¹„ì •ìƒ í˜¸í¡ìŒ íŒ¨í„´ (ê³ ì£¼íŒŒìˆ˜ ê°•í•¨)
        spec = np.random.randn(200, 128)
        spec[:, 64:] *= 2  # ê³ ì£¼íŒŒìˆ˜ ê°•í™”
    
    dummy_data.append(spec)

print(f"ìƒì„±ëœ ë”ë¯¸ ë°ì´í„°: {len(dummy_data)}ê°œ")
print(f"ê° ë°ì´í„° shape: {dummy_data[0].shape}")

# AudioDataset í…ŒìŠ¤íŠ¸
print("\nAudioDataset í…ŒìŠ¤íŠ¸...")
dataset = AudioDataset(dummy_data, max_len=128, augment=True, method="cola")
print(f"Dataset í¬ê¸°: {len(dataset)}")

# ì²« ë²ˆì§¸ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
x1, x2 = dataset[0]
print(f"x1 shape: {x1.shape}")
print(f"x2 shape: {x2.shape}")
print(f"x1ì™€ x2ê°€ ë‹¤ë¥¸ê°€? {not np.array_equal(x1, x2)}")
print(f"x1ì™€ x2ì˜ ìœ ì‚¬ë„: {np.corrcoef(x1.flatten(), x2.flatten())[0,1]:.3f}")

# DataLoader í…ŒìŠ¤íŠ¸
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
batch_x1, batch_x2 = next(iter(dataloader))
print(f"ë°°ì¹˜ x1 shape: {batch_x1.shape}")
print(f"ë°°ì¹˜ x2 shape: {batch_x2.shape}")

print("\nğŸ”¬ 4ë‹¨ê³„: Cola ëª¨ë¸ ìƒì„¸ ë¶„ì„")
print("-" * 50)

# ê°„ë‹¨í•œ ì¸ì½”ë” ìƒì„±
encoder = SimpleEncoder(input_dim=128, hidden_dim=512, output_dim=768)
print(f"ì¸ì½”ë” íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in encoder.parameters()):,}")

# Cola ëª¨ë¸ ìƒì„±
cola_model = Cola(encoder, projection_dim=256, learning_rate=1e-4)
print(f"Cola ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in cola_model.parameters()):,}")

print("""
ğŸ“‹ Cola ëª¨ë¸ì˜ êµ¬ì¡°:

1. Encoder (SimpleEncoder):
   - ì…ë ¥: [batch_size, time_frames, mel_bins]
   - ì¶œë ¥: [batch_size, 768] (ê³ ì°¨ì› íŠ¹ì§•)

2. Projection Head:
   - ì…ë ¥: [batch_size, 768]
   - ì¶œë ¥: [batch_size, 256] (ëŒ€ì¡° í•™ìŠµìš© íŠ¹ì§•)

3. Contrastive Loss:
   - Positive pairs: ê°™ì€ ì˜¤ë””ì˜¤ì˜ ë³€í˜•ë“¤ â†’ ê°€ê¹ê²Œ
   - Negative pairs: ë‹¤ë¥¸ ì˜¤ë””ì˜¤ì˜ ë³€í˜•ë“¤ â†’ ë©€ê²Œ
""")

# ëª¨ë¸ forward í…ŒìŠ¤íŠ¸
print("\nëª¨ë¸ forward í…ŒìŠ¤íŠ¸...")
cola_model.eval()
with torch.no_grad():
    proj_1, proj_2 = cola_model(batch_x1.float(), batch_x2.float())
    print(f"í”„ë¡œì ì…˜ 1 shape: {proj_1.shape}")
    print(f"í”„ë¡œì ì…˜ 2 shape: {proj_2.shape}")
    
    # Contrastive Loss ê³„ì‚°
    loss = cola_model.contrastive_loss(proj_1, proj_2)
    print(f"Contrastive Loss: {loss.item():.4f}")

print("\nğŸ§  5ë‹¨ê³„: ColaMD ëª¨ë¸ ë¶„ì„")
print("-" * 50)

# ColaMD ëª¨ë¸ ìƒì„±
colamd_model = ColaMD(encoder, projection_dim=256, learning_rate=1e-4)
print(f"ColaMD ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in colamd_model.parameters()):,}")

print("""
ğŸ“‹ ColaMD vs Cola ì°¨ì´ì :

Cola (ì¼ë°˜ ì˜¤ë””ì˜¤):
- ê¸°ë³¸ì ì¸ Contrastive Learning
- ì¼ë°˜ì ì¸ ì˜¤ë””ì˜¤ ë°ì´í„°ì— ìµœì í™”

ColaMD (ì˜ë£Œ ë°ì´í„°):
- ì˜ë£Œ ë°ì´í„° íŠ¹í™”
- ë” ê°•í•œ ëŒ€ì¡° í•™ìŠµ (2ë°° í˜ë„í‹°)
- í˜¸í¡ìŒì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„
""")

# ColaMD í…ŒìŠ¤íŠ¸
print("\nColaMD ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
colamd_model.eval()
with torch.no_grad():
    proj_1, proj_2 = colamd_model(batch_x1.float(), batch_x2.float())
    loss = colamd_model.contrastive_loss(proj_1, proj_2)
    print(f"ColaMD Contrastive Loss: {loss.item():.4f}")

print("\nğŸ¯ 6ë‹¨ê³„: Self-Supervised Learningì˜ ì‘ë™ ì›ë¦¬")
print("-" * 50)

print("""
ğŸ”„ Self-Supervised Learning ê³¼ì •:

1. ë°ì´í„° ì¤€ë¹„:
   - ë¼ë²¨ ì—†ëŠ” ëŒ€ëŸ‰ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°
   - ê° ì˜¤ë””ì˜¤ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë³€í˜• ìƒì„±

2. Positive Pairs ìƒì„±:
   - ê°™ì€ ì˜¤ë””ì˜¤ â†’ random_crop â†’ x1, x2
   - x1ê³¼ x2ëŠ” ê°™ì€ ë‚´ìš©ì˜ ë‹¤ë¥¸ êµ¬ê°„

3. Negative Pairs ìƒì„±:
   - ë‹¤ë¥¸ ì˜¤ë””ì˜¤ â†’ random_crop â†’ x3, x4
   - x1ê³¼ x3ì€ ë‹¤ë¥¸ ë‚´ìš©

4. Contrastive Learning:
   - Positive pairs (x1, x2): ê°€ê¹ê²Œ í•™ìŠµ
   - Negative pairs (x1, x3): ë©€ê²Œ í•™ìŠµ

5. íŠ¹ì§• í•™ìŠµ:
   - ëª¨ë¸ì´ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§•ì„ ìë™ìœ¼ë¡œ í•™ìŠµ
   - ë¼ë²¨ ì—†ì´ë„ ë°ì´í„°ì˜ ë³¸ì§ˆì ì¸ íŠ¹ì„± íŒŒì•…
""")

print("\nğŸ”¬ 7ë‹¨ê³„: ì‹¤ì œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜")
print("-" * 50)

# ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
print("ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜...")

# ë” í° ë°ì´í„°ì…‹ ìƒì„±
large_dataset = []
for i in range(100):
    spec = np.random.randn(200, 128)
    large_dataset.append(spec)

# DataLoader ìƒì„±
large_dataloader = DataLoader(
    AudioDataset(large_dataset, max_len=128, augment=True, method="cola"),
    batch_size=8, shuffle=True
)

# ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
cola_model.train()

# ëª‡ ê°œì˜ ë°°ì¹˜ë¡œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
total_loss = 0
for i, (batch_x1, batch_x2) in enumerate(large_dataloader):
    if i >= 5:  # 5ê°œ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
        break
    
    # Forward pass
    proj_1, proj_2 = cola_model(batch_x1.float(), batch_x2.float())
    loss = cola_model.contrastive_loss(proj_1, proj_2)
    total_loss += loss.item()
    
    print(f"ë°°ì¹˜ {i+1}: Loss = {loss.item():.4f}")

avg_loss = total_loss / 5
print(f"í‰ê·  Loss: {avg_loss:.4f}")

print("\nğŸ“ 8ë‹¨ê³„: í•µì‹¬ ê°œë… ì •ë¦¬")
print("-" * 50)

print("""
ğŸ¯ pretrain.ipynbì˜ í•µì‹¬ ê°œë…:

1. Self-Supervised Learning:
   - ë¼ë²¨ ì—†ëŠ” ë°ì´í„°ë¡œ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• í•™ìŠµ
   - Contrastive Learning ë°©ì‹ ì‚¬ìš©
   - Positive/Negative pairs í•™ìŠµ

2. AudioDataset:
   - ê°™ì€ ì˜¤ë””ì˜¤ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë³€í˜• ìƒì„±
   - random_cropìœ¼ë¡œ ì‹œê°„ì  ë‹¤ì–‘ì„± í™•ë³´
   - random_maskë¡œ ë…¸ì´ì¦ˆ ê°•ê±´ì„± í–¥ìƒ

3. Cola/ColaMD ëª¨ë¸:
   - Encoder: ì˜¤ë””ì˜¤ â†’ ê³ ì°¨ì› íŠ¹ì§•
   - Projection Head: ëŒ€ì¡° í•™ìŠµìš© íŠ¹ì§• ë³€í™˜
   - Contrastive Loss: PositiveëŠ” ê°€ê¹ê²Œ, NegativeëŠ” ë©€ê²Œ

4. ì˜ë£Œ ë°ì´í„° íŠ¹í™”:
   - ColaMD: ì˜ë£Œ ë°ì´í„°ì— íŠ¹í™”ëœ ëŒ€ì¡° í•™ìŠµ
   - í˜¸í¡ìŒì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„
   - ë” ê°•í•œ ëŒ€ì¡° í•™ìŠµìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• ì¶”ì¶œ

5. í•™ìŠµ ê³¼ì •:
   - ëŒ€ëŸ‰ì˜ ë¼ë²¨ ì—†ëŠ” ë°ì´í„° í™œìš©
   - ìë™ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• í•™ìŠµ
   - ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— í™œìš© ê°€ëŠ¥í•œ ì¼ë°˜í™”ëœ íŠ¹ì§•
""")

print("\nâœ… pretrain.ipynb ì™„ì „ ì´í•´ ì™„ë£Œ!")
print("=" * 70)
