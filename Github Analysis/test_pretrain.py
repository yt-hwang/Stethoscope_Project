#!/usr/bin/env python3
"""
Pretrain Notebook í…ŒìŠ¤íŠ¸
- Self-Supervised Learning êµ¬í˜„ í…ŒìŠ¤íŠ¸
"""

print("ğŸš€ Pretrain Notebook í…ŒìŠ¤íŠ¸ ì‹œì‘!")
print("=" * 50)

# Cell 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ import
print("\nğŸ“¦ 1ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ import")
print("-" * 30)

import numpy as np
import os
import random
import math
import time
import pandas as pd
import librosa
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger
# from lightning.pytorch.utilities import CombinedLoader  # í•„ìš”ì‹œ ì‚¬ìš©

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤ import
from src.util import random_crop, random_mask, random_multiply
from src.model.models_cola import Cola, ColaMD, SimpleEncoder

print("âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!")

# Cell 2: AudioDataset í´ë˜ìŠ¤ ì •ì˜
print("\nğŸ”§ 2ë‹¨ê³„: AudioDataset í´ë˜ìŠ¤ ì •ì˜")
print("-" * 30)

class AudioDataset(torch.utils.data.Dataset):
    """
    ì˜¤ë””ì˜¤ (ìŠ¤í™íŠ¸ë¡œê·¸ë¨) ë°ì´í„°ë¥¼ contrastive í•™ìŠµ ë°©ì‹(cola)ì— ë§ê²Œ
    x1, x2ë¡œ ì¦ê°•í•˜ì—¬ ë¦¬í„´í•˜ëŠ” Dataset í´ë˜ìŠ¤
    """
    def __init__(
        self, data, max_len=200, augment=True, from_npy=False,
        labels=None, method="cola"
    ):
        """
        Args:
            data: íŒŒì¼ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ or numpy ë°°ì—´ ë¦¬ìŠ¤íŠ¸
            max_len: random_crop ì‹œ ì‚¬ìš©í•  í¬ê¸°
            augment: Trueë©´ random_mask, random_multiply ê°™ì€ ì¦ê°• ì ìš©
            from_npy: Trueë©´ data[idx]+".npy" íŒŒì¼ì„ ë¡œë“œ
            labels: ì§€ë„í•™ìŠµ ì‹œ í•„ìš”í•œ ë ˆì´ë¸” (ì—†ìœ¼ë©´ None)
            method: "cola" (contrastive)
        """
        self.data = data
        self.max_len = max_len
        self.augment = augment
        self.from_npy = from_npy
        self.labels = labels
        self.method = method

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # npy íŒŒì¼ë¡œë¶€í„° ë¡œë“œí• ì§€ ì—¬ë¶€ ê²°ì •
        if self.from_npy:
            npy_path = self.data[idx]
            x = np.load(npy_path)
        else:
            x = self.data[idx]

        if self.method == "cola":
            # ì½œë¼ ë°©ì‹ ì¦ê°•
            if self.augment:
                x = random_mask(x)

            x1 = random_crop(x, crop_size=self.max_len)
            x2 = random_crop(x, crop_size=self.max_len)
            
            return x1, x2
        else:
            # ì¼ë°˜ì ì¸ ê²½ìš°
            if self.labels is not None:
                return x, self.labels[idx]
            else:
                return x

print("âœ… AudioDataset í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!")

# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
print("\nğŸ§ª 3ë‹¨ê³„: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±")
print("-" * 30)

# ë”ë¯¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë°ì´í„° ìƒì„±
def create_dummy_spectrogram_data(num_samples=100, time_frames=200, mel_bins=128):
    """ë”ë¯¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë°ì´í„° ìƒì„±"""
    data = []
    for i in range(num_samples):
        # ëœë¤í•œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
        spec = np.random.randn(time_frames, mel_bins)
        data.append(spec)
    return data

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
dummy_data = create_dummy_spectrogram_data(num_samples=50, time_frames=200, mel_bins=128)
print(f"ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(dummy_data)}ê°œ ìƒ˜í”Œ")
print(f"ê° ìƒ˜í”Œ shape: {dummy_data[0].shape}")

# AudioDataset í…ŒìŠ¤íŠ¸
print("\nğŸ” 4ë‹¨ê³„: AudioDataset í…ŒìŠ¤íŠ¸")
print("-" * 30)

dataset = AudioDataset(dummy_data, max_len=128, augment=True, method="cola")
print(f"Dataset í¬ê¸°: {len(dataset)}")

# ì²« ë²ˆì§¸ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
x1, x2 = dataset[0]
print(f"x1 shape: {x1.shape}")
print(f"x2 shape: {x2.shape}")
print(f"x1ì™€ x2ê°€ ë‹¤ë¥¸ê°€? {not np.array_equal(x1, x2)}")

# DataLoader í…ŒìŠ¤íŠ¸
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
print(f"DataLoader ë°°ì¹˜ ìˆ˜: {len(dataloader)}")

# ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
batch_x1, batch_x2 = next(iter(dataloader))
# ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€í™˜
batch_x1 = batch_x1.float()
batch_x2 = batch_x2.float()
print(f"ë°°ì¹˜ x1 shape: {batch_x1.shape}, dtype: {batch_x1.dtype}")
print(f"ë°°ì¹˜ x2 shape: {batch_x2.shape}, dtype: {batch_x2.dtype}")

# ëª¨ë¸ í…ŒìŠ¤íŠ¸
print("\nğŸ” 5ë‹¨ê³„: ëª¨ë¸ í…ŒìŠ¤íŠ¸")
print("-" * 30)

# ê°„ë‹¨í•œ ì¸ì½”ë” ìƒì„±
encoder = SimpleEncoder(input_dim=128, hidden_dim=512, output_dim=768)
print(f"ì¸ì½”ë” íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in encoder.parameters())}")

# Cola ëª¨ë¸ ìƒì„±
cola_model = Cola(encoder, projection_dim=256, learning_rate=1e-4)
print(f"Cola ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in cola_model.parameters())}")

# ColaMD ëª¨ë¸ ìƒì„±
colamd_model = ColaMD(encoder, projection_dim=256, learning_rate=1e-4)
print(f"ColaMD ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in colamd_model.parameters())}")

# ëª¨ë¸ forward í…ŒìŠ¤íŠ¸
cola_model.eval()
with torch.no_grad():
    proj_1, proj_2 = cola_model(batch_x1, batch_x2)
    print(f"í”„ë¡œì ì…˜ 1 shape: {proj_1.shape}")
    print(f"í”„ë¡œì ì…˜ 2 shape: {proj_2.shape}")

# ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
loss = cola_model.contrastive_loss(proj_1, proj_2)
print(f"Contrastive Loss: {loss.item():.4f}")

print("\nğŸ¯ í•µì‹¬ ê°œë… ì •ë¦¬")
print("-" * 30)
print("1. AudioDataset: ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Contrastive Learningìš©ìœ¼ë¡œ ë³€í™˜")
print("2. random_crop: ê°™ì€ ì˜¤ë””ì˜¤ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ êµ¬ê°„ ì¶”ì¶œ (Positive pairs)")
print("3. random_mask: ë…¸ì´ì¦ˆ ê°•ê±´ì„±ì„ ìœ„í•œ ë§ˆìŠ¤í‚¹")
print("4. Cola: Contrastive Learning for Audio")
print("5. ColaMD: ì˜ë£Œ ë°ì´í„° íŠ¹í™” Cola ëª¨ë¸")
print("6. Contrastive Loss: Positive pairsëŠ” ê°€ê¹ê²Œ, Negative pairsëŠ” ë©€ê²Œ")

print("\nâœ… Pretrain Notebook í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("=" * 50)
